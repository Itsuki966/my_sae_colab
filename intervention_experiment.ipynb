{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d9b08f",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8755ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colabç’°å¢ƒã‹ã©ã†ã‹ã‚’ç¢ºèª\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"âœ… Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"âœ… Running in local environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107a22b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colabç’°å¢ƒã®å ´åˆã€å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸ“¦ Installing required packages...\")\n",
    "    !pip install -q transformer-lens sae-lens einops jaxtyping datasets huggingface_hub\n",
    "    print(\"âœ… Installation completed\")\n",
    "else:\n",
    "    print(\"â„¹ï¸  Skipping package installation (local environment)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c292601",
   "metadata": {},
   "source": [
    "## 2. Google Driveã®ãƒã‚¦ãƒ³ãƒˆï¼ˆColabç’°å¢ƒã®å ´åˆï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41cb4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•\n",
    "    project_path = '/content/drive/MyDrive/sae_pj2'\n",
    "    os.chdir(project_path)\n",
    "    print(f\"âœ… Changed directory to: {project_path}\")\n",
    "else:\n",
    "    print(\"â„¹ï¸  Skipping Google Drive mount (local environment)\")\n",
    "\n",
    "print(f\"ğŸ“‚ Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdacc0ea",
   "metadata": {},
   "source": [
    "## 3. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ \n",
    "if IN_COLAB:\n",
    "    sys.path.append('/content/drive/MyDrive/sae_pj2')\n",
    "\n",
    "# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "from intervention_runner import InterventionRunner\n",
    "from config import INTERVENTION_GEMMA2_9B_IT_CONFIG\n",
    "\n",
    "print(\"âœ… Modules imported successfully\")\n",
    "\n",
    "# GPUã®ç¢ºèª\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ğŸ® GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ No GPU available. Using CPU (this will be slow)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1502421d",
   "metadata": {},
   "source": [
    "## 4. ä»‹å…¥å¯¾è±¡ã®ç‰¹å¾´é‡IDã‚’æŒ‡å®š\n",
    "\n",
    "Step 4 ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã§ç‰¹å®šã•ã‚ŒãŸè¿åˆæ€§ç‰¹å¾´é‡ã®IDãƒªã‚¹ãƒˆã‚’æŒ‡å®šã—ã¾ã™ã€‚\n",
    "\n",
    "**ä¾‹**: Attribution Patching ã®çµæœã‹ã‚‰ã€ä¸Šä½20å€‹ã®ç‰¹å¾´é‡ã‚’é¸æŠã—ãŸå ´åˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf1aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ã€é‡è¦ã€‘ã“ã“ã«ä»‹å…¥å¯¾è±¡ã®ç‰¹å¾´é‡IDãƒªã‚¹ãƒˆã‚’æŒ‡å®šã—ã¦ãã ã•ã„\n",
    "# ============================================================\n",
    "\n",
    "# ä¾‹: Step 4 ã§ç‰¹å®šã•ã‚ŒãŸä¸Šä½20å€‹ã®è¿åˆæ€§ç‰¹å¾´é‡\n",
    "intervention_feature_ids = [\n",
    "    123, 456, 789, 1024, 2048,  # å®Ÿéš›ã®IDã«ç½®ãæ›ãˆã¦ãã ã•ã„\n",
    "    3072, 4096, 5120, 6144, 7168,\n",
    "    8192, 9216, 10240, 11264, 12288,\n",
    "    13312, 14336, 15360, 16000, 16383\n",
    "]\n",
    "\n",
    "# ã¾ãŸã¯ã€JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€å ´åˆ:\n",
    "# import json\n",
    "# with open('results/selected_features.json', 'r') as f:\n",
    "#     data = json.load(f)\n",
    "#     intervention_feature_ids = data['top_k_features']\n",
    "\n",
    "print(f\"ğŸ¯ Intervention target: {len(intervention_feature_ids)} features\")\n",
    "print(f\"   Feature IDs: {intervention_feature_ids[:5]}... (showing first 5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb86a3f",
   "metadata": {},
   "source": [
    "## 5. å®Ÿé¨“è¨­å®šã®ç¢ºèªã¨èª¿æ•´\n",
    "\n",
    "å¿…è¦ã«å¿œã˜ã¦ã€å®Ÿé¨“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead2ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨­å®šã‚’ã‚³ãƒ”ãƒ¼ã—ã¦èª¿æ•´ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "from copy import deepcopy\n",
    "from config import DataConfig, GenerationConfig\n",
    "\n",
    "# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è¨­å®šã‚’ä½¿ç”¨\n",
    "config = INTERVENTION_GEMMA2_9B_IT_CONFIG\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’èª¿æ•´ã—ãŸã„å ´åˆï¼ˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œç”¨ï¼‰\n",
    "# config.data.sample_size = 5  # ä¾‹: æœ€åˆã®5å•ã®ã¿ã§å®Ÿé¨“\n",
    "\n",
    "# ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã—ãŸã„å ´åˆ\n",
    "# config.generation.temperature = 0.5\n",
    "# config.generation.max_new_tokens = 100\n",
    "\n",
    "print(\"âš™ï¸  Experiment Configuration:\")\n",
    "print(f\"   Model: {config.model.name}\")\n",
    "print(f\"   SAE: {config.model.sae_release}/{config.model.sae_id}\")\n",
    "print(f\"   Hook: {config.model.hook_name}\")\n",
    "print(f\"   Sample size: {config.data.sample_size}\")\n",
    "print(f\"   Max new tokens: {config.generation.max_new_tokens}\")\n",
    "print(f\"   Temperature: {config.generation.temperature}\")\n",
    "print(f\"   Dataset: {config.data.dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5759ca",
   "metadata": {},
   "source": [
    "## 6. ä»‹å…¥å®Ÿé¨“ã®å®Ÿè¡Œ\n",
    "\n",
    "InterventionRunnerã‚’åˆæœŸåŒ–ã—ã¦å®Ÿé¨“ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e61fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InterventionRunnerã®åˆæœŸåŒ–\n",
    "runner = InterventionRunner(\n",
    "    config=config,\n",
    "    intervention_feature_ids=intervention_feature_ids\n",
    ")\n",
    "\n",
    "print(\"âœ… InterventionRunner initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba69a14",
   "metadata": {},
   "source": [
    "### ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ãƒ‡ãƒ¼ã‚¿ç¯„å›²ã‚’æŒ‡å®šã—ã¦å®Ÿé¨“ã‚’å®Ÿè¡Œ\n",
    "\n",
    "å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹å ´åˆã€ç¯„å›²ã‚’æŒ‡å®šã—ã¦æ®µéšçš„ã«å®Ÿè¡Œã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3c1fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®Ÿé¨“å®Ÿè¡Œã®ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
    "\n",
    "# ãƒ‘ã‚¿ãƒ¼ãƒ³1: è¨­å®šã§æŒ‡å®šã—ãŸsample_sizeåˆ†ã ã‘å®Ÿè¡Œ\n",
    "output_path = runner.run_complete_experiment()\n",
    "\n",
    "# ãƒ‘ã‚¿ãƒ¼ãƒ³2: sample_sizeã‚’ç›´æ¥æŒ‡å®š\n",
    "# output_path = runner.run_complete_experiment(sample_size=10)\n",
    "\n",
    "# ãƒ‘ã‚¿ãƒ¼ãƒ³3: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç¯„å›²ã‚’æŒ‡å®šï¼ˆ0-basedï¼‰\n",
    "# ä¾‹: 101å•ç›®ã‹ã‚‰200å•ç›®ã¾ã§ (index 100-199)\n",
    "# output_path = runner.run_complete_experiment(start_index=100, end_index=200)\n",
    "\n",
    "print(f\"\\nâœ… Experiment completed!\")\n",
    "print(f\"ğŸ“ Results saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb44c263",
   "metadata": {},
   "source": [
    "## 7. çµæœã®ç¢ºèª\n",
    "\n",
    "ä¿å­˜ã•ã‚ŒãŸçµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã€ç°¡å˜ãªç¢ºèªã‚’è¡Œã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9261cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿\n",
    "with open(output_path, 'r', encoding='utf-8') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "print(\"ğŸ“Š Experiment Results Summary:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {results['metadata']['model_name']}\")\n",
    "print(f\"Intervention method: {results['metadata']['intervention_method']}\")\n",
    "print(f\"Number of intervention features: {results['metadata']['num_intervention_features']}\")\n",
    "print(f\"Total questions processed: {results['metadata']['num_questions']}\")\n",
    "print(f\"Question ID range: {results['metadata']['question_id_range']['start']} - {results['metadata']['question_id_range']['end']}\")\n",
    "print(f\"Timestamp: {results['metadata']['timestamp']}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e90cc",
   "metadata": {},
   "source": [
    "### ã‚µãƒ³ãƒ—ãƒ«çµæœã®è¡¨ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc764d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€åˆã®è³ªå•ã®çµæœã‚’è©³ã—ãè¡¨ç¤º\n",
    "if results['results']:\n",
    "    first_question = results['results'][0]\n",
    "    \n",
    "    print(\"\\nğŸ“ Sample Result (Question 1):\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Dataset: {first_question['dataset']}\")\n",
    "    print(f\"Base text: {first_question['base_text'][:100]}...\")\n",
    "    print(f\"\\nNumber of variations: {len(first_question['variations'])}\")\n",
    "    \n",
    "    # æœ€åˆã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã®è©³ç´°\n",
    "    first_variation = first_question['variations'][0]\n",
    "    print(f\"\\n--- Variation 1: {first_variation['template']} ---\")\n",
    "    print(f\"Prompt: {first_variation['prompt'][:150]}...\")\n",
    "    print(f\"\\nBaseline Response:\")\n",
    "    print(f\"  {first_variation['baseline_response']}\")\n",
    "    print(f\"\\nIntervention Response:\")\n",
    "    print(f\"  {first_variation['intervention_response']}\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"âš ï¸ No results found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fbfb02",
   "metadata": {},
   "source": [
    "## 8. å¿œç­”ã®æ¯”è¼ƒåˆ†æï¼ˆç°¡æ˜“ç‰ˆï¼‰\n",
    "\n",
    "Baselineã¨Interventionã®å¿œç­”ãŒç•°ãªã‚‹ã‚±ãƒ¼ã‚¹ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f43536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿œç­”ãŒå¤‰åŒ–ã—ãŸã‚±ãƒ¼ã‚¹ã‚’ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "total_variations = 0\n",
    "changed_variations = 0\n",
    "\n",
    "for question in results['results']:\n",
    "    for variation in question['variations']:\n",
    "        total_variations += 1\n",
    "        baseline = variation['baseline_response'].strip()\n",
    "        intervention = variation['intervention_response'].strip()\n",
    "        \n",
    "        if baseline != intervention:\n",
    "            changed_variations += 1\n",
    "\n",
    "change_rate = (changed_variations / total_variations * 100) if total_variations > 0 else 0\n",
    "\n",
    "print(\"\\nğŸ“ˆ Response Change Analysis:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total variations processed: {total_variations}\")\n",
    "print(f\"Variations with changed response: {changed_variations}\")\n",
    "print(f\"Change rate: {change_rate:.2f}%\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nâ„¹ï¸  Next steps:\")\n",
    "print(\"  1. Use GPT-4o to evaluate sycophancy flags for baseline vs intervention\")\n",
    "print(\"  2. Use GPT-4o to rate naturalness scores (1-5 scale)\")\n",
    "print(\"  3. Perform McNemar's test for statistical significance\")\n",
    "print(\"  4. Analyze qualitative changes in response content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9c4aae",
   "metadata": {},
   "source": [
    "## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "å®Ÿé¨“çµæœã‚’ç”¨ã„ã¦ã€ä»¥ä¸‹ã®è©•ä¾¡ã‚’è¡Œã„ã¾ã™ï¼š\n",
    "\n",
    "1. **Sycophancy Rate (è¿åˆç‡) ã®è©•ä¾¡**\n",
    "   - GPT-4o ã‚’ç”¨ã„ã¦ Baseline ã¨ Intervention ã®å¿œç­”ã«å¯¾ã—ã¦è¿åˆãƒ•ãƒ©ã‚°ã‚’åˆ¤å®š\n",
    "   - è¿åˆç‡ã®å¤‰åŒ–ã‚’è¨ˆç®—\n",
    "   - McNemaræ¤œå®šã§çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’æ¤œè¨¼\n",
    "\n",
    "2. **Naturalness Score (è‡ªç„¶ã•ã‚¹ã‚³ã‚¢) ã®è©•ä¾¡**\n",
    "   - GPT-4o ã‚’ç”¨ã„ã¦1-5ã®ãƒªãƒƒã‚«ãƒ¼ãƒˆå°ºåº¦ã§è©•ä¾¡\n",
    "   - ä»‹å…¥ã«ã‚ˆã‚‹è‡ªç„¶ã•ã®ä½ä¸‹ãŒãªã„ã‹ç¢ºèª\n",
    "\n",
    "3. **å®šæ€§åˆ†æ**\n",
    "   - å¿œç­”ãŒã©ã®ã‚ˆã†ã«å¤‰åŒ–ã—ãŸã‹ã‚’è©³ã—ãåˆ†æ\n",
    "   - ç‰¹ã«åŠ¹æœçš„ã ã£ãŸã‚±ãƒ¼ã‚¹ã¨åŠ¹æœãŒãªã‹ã£ãŸã‚±ãƒ¼ã‚¹ã‚’æ¯”è¼ƒ\n",
    "\n",
    "ã“ã‚Œã‚‰ã®è©•ä¾¡ã¯åˆ¥ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¾ãŸã¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å®Ÿæ–½ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
